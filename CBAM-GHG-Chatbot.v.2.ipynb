{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "pvw5zaulfvnudyugal3p",
   "authorId": "3248219620606",
   "authorName": "MSMAISA",
   "authorEmail": "maria.zvezdkina@gmail.com",
   "sessionId": "c7bf4481-428c-4a45-a705-3659eca08685",
   "lastEditTime": 1762212219819
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2d13f5-e982-4f75-b5a0-41a7f0befc50",
   "metadata": {
    "collapsed": false,
    "name": "INTRO_MD",
    "resultHeight": 298
   },
   "source": [
    "# Getting Started with â„ï¸ Anthropic on Snowflake Cortex\n",
    "\n",
    "Build an intelligent question-answering system using Anthropic's Claude and Snowflake's AI capabilities.âš¡ï¸\n",
    "\n",
    "This notebook demonstrates how to build an end-to-end application that:\n",
    "1. Processes PDF documents using Cortex Process Docouments\n",
    "2. Creates Cortex Search Service to do keyword and vector searches\n",
    "3. Implements a chat interface using Snowflake's Cortex and Anthropic's Claude in Streamlit\n",
    "\n",
    "Check out the [Quickstart](https://quickstarts.snowflake.com/guide/getting_started_on_anthropic_with_snowflake_cortex) for instructions on getting setup for this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292396c3-271e-4760-949d-a018ae2ecaae",
   "metadata": {
    "collapsed": false,
    "name": "SETUP_ENVIRONMENT_MD",
    "resultHeight": 172
   },
   "source": [
    "## Setting Up Your Environment ðŸŽ’\n",
    "\n",
    "First, we'll import the required packages and set up our Snowflake session. The notebook uses several key packages:\n",
    "- `streamlit`: For creating the interactive chat interface\n",
    "- `snowflake-ml-python`: For Snowflake Cortex for embeddings and LLM capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "IMPORT_PACKAGES",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.cortex import complete, EmbedText768\n",
    "from snowflake.snowpark.types import VectorType, FloatType\n",
    "from snowflake.core.table import Table, TableColumn\n",
    "from snowflake.core import CreateMode, Root\n",
    "from snowflake.snowpark.functions import cast, col\n",
    "\n",
    "\n",
    "session = get_active_session()\n",
    "current_warehouse = session.get_current_warehouse()\n",
    "database_name = session.get_current_database()\n",
    "schema_name = session.get_current_schema()\n",
    "role_name = session.get_current_role()\n",
    "service_name = 'document_search_service'\n",
    "root = Root(session)\n",
    "database = root.databases[database_name]\n",
    "schema = database.schemas[schema_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf55b1e-27f2-4c48-b2f9-2c28a5fd6f26",
   "metadata": {
    "collapsed": false,
    "name": "SETUP_STAGE_VARIABLES_MD",
    "resultHeight": 102
   },
   "source": [
    "## Setting Up Stage Variables ðŸ“\n",
    "\n",
    "We'll define our stage name and retrieve the list of files to process. This stage should contain the PDF documents we want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba83db-cebb-4135-b42e-cd914d04979c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "VARIABLES",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "stage_name=\"@Documents\"\n",
    "files = session.sql(f\"LIST{stage_name}\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1c904-ac79-4687-abbc-ff58476cbfdb",
   "metadata": {
    "collapsed": false,
    "name": "DOCUMENT_PROCESSING_MD",
    "resultHeight": 102
   },
   "source": [
    "## Document Processing Functions ðŸ“„\n",
    "\n",
    "We'll create functions to extract text from PDF files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb862d46-00a2-4c0f-b2f2-f2aa9fd4b932",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DOCUMENT_PROCESSING",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "def process(file_name: str):\n",
    "    query = \"\"\"\n",
    "        SELECT TO_VARCHAR(\n",
    "            SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "                ?,\n",
    "                ?,\n",
    "                {'mode': 'OCR'}):content\n",
    "        ) AS OCR;\n",
    "    \"\"\"\n",
    "\n",
    "    resp = session.sql(query, params=[stage_name, file_name]).collect()\n",
    "    text = resp[0]['OCR']\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'TEXT' : [text],\n",
    "        'FILE_NAME': file_name\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf82656-1bcb-45ea-9922-431013d3b5eb",
   "metadata": {
    "collapsed": false,
    "name": "CREATE_EMBEDDINGS_MD",
    "resultHeight": 172
   },
   "source": [
    "## Processing Documents\n",
    "\n",
    "Now we'll:\n",
    "1. Process all documents in our stage\n",
    "2. Store the results in our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca313e-5d8a-4eac-9566-7ab1ca5cc381",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "PROCESS_FILES",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Extract file names and process files\n",
    "file_names = [file['name'].split('/')[1] for file in files]\n",
    "\n",
    "# Download and process files into a DataFrame\n",
    "final_dataframe = pd.concat([\n",
    "    process(file_name)\n",
    "    for file_name in file_names\n",
    "], ignore_index=True)\n",
    "\n",
    "snowpark_df = session.create_dataframe(final_dataframe).select(\n",
    "    col(\"file_name\"),\n",
    "    col(\"text\")\n",
    ")\n",
    "\n",
    "# Write the transformed data directly to the target table\n",
    "snowpark_df.write.mode(\"overwrite\").save_as_table(\"docs_text_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd481dc-b606-4fec-8753-7759aabed213",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "## Create Cortex Search Service \n",
    "\n",
    "### Key Components Explained ðŸ“š\n",
    "\n",
    "#### Required Parameters\n",
    "\n",
    "- `ON`: Specifies the column containing the text to be indexed  \n",
    "- `ATTRIBUTES`: Additional columns to include in search results (e.g., file\\_name)  \n",
    "- `WAREHOUSE`: Compute warehouse for processing the embeddings  \n",
    "- `TARGET_LAG`: Maximum allowed lag for index updates  \n",
    "- `EMBEDDING_MODEL`: Model used to generate text embeddings  \n",
    "- Source query: The SELECT statement defining the data to index\n",
    "\n",
    "#### Configuration Options ðŸ”§\n",
    "\n",
    "1. Target Lag Settings:  \n",
    "     \n",
    "   - Shorter lag times mean more frequent updates  \n",
    "   - Common values: '1 hour', '1 day', '1 week'  \n",
    "   - Balance freshness needs with compute costs\n",
    "\n",
    "   \n",
    "\n",
    "2. Embedding Model Options:  \n",
    "     \n",
    "   - 'snowflake-arctic-embed-l-v2.0': Latest Snowflake embedding model  \n",
    "   - Optimized for English language content  \n",
    "   - 384-dimensional embeddings\n",
    "\n",
    "   \n",
    "\n",
    "3. Warehouse Considerations:  \n",
    "     \n",
    "   - Choose size based on data volume  \n",
    "   - Consider compute costs vs update frequency  \n",
    "   - Monitor warehouse utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe7945-d6a7-4309-a331-a67b1123238d",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CREATE_CORTEX_SEARCH_SERVICE",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE CORTEX SEARCH SERVICE {{service_name}}\n",
    "  ON text\n",
    "  ATTRIBUTES file_name\n",
    "  WAREHOUSE = {{current_warehouse}}\n",
    "  TARGET_LAG = '1 day'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "  AS (\n",
    "    SELECT\n",
    "        text,\n",
    "        file_name\n",
    "    FROM docs_text_table\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca153ba-92e0-4cd2-8e0c-343d781aead3",
   "metadata": {
    "collapsed": false,
    "name": "BUILD_CHAT_INTERFACE_MD",
    "resultHeight": 371
   },
   "source": "## Building the Chat Interface ðŸ’¬\n\nFinally, we'll create our chat interface that uses:\n- Utilizes the Cortex Search Service for finding relevant context\n- Chat history management for conversation continuity\n- Anthropic's Claude model for generating responses\n- Streamlit for the user interface\n\nKey parameters:\n- `num_results`: Number of context results provided (default: 3)\n- `model_name`: Language model used (default: \"claude-haiku-4-5\")\n- `history_length`: Chat history length (default: 5)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc57aa3-082f-4cc4-a7b0-e01c56ee6d90",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "BUILD_CHAT_INTERFACE",
    "resultHeight": 3622
   },
   "outputs": [],
   "source": "import streamlit as st\nimport json\nimport time\nimport re\nimport pandas as pd\nfrom snowflake.core import Root\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import col\nfrom snowflake.cortex import complete\nfrom datetime import datetime\n\n# Snowflake session setup\nsession = get_active_session()\nroot = Root(session)\ndatabase_name = session.get_current_database()\nschema_name = session.get_current_schema()\nservice_name = 'document_search_service'\n\n# Configuration\nmodel_name = \"claude-haiku-4-5\"\nnum_results = 3\nhistory_length = 5\nDEFAULT_CARBON_PRICE = 78.54  # Current market price as of Oct 31, 2025\nMIN_REQUEST_INTERVAL = 2.0\nRETRY_DELAY = 5\n\n# Recent EU ETS prices from October 2025\n# Source: Trading Economics (tradingeconomics.com/commodity/carbon)\nRECENT_PRICES = {\n    \"2025-10-31\": 78.54,\n    \"2025-10-01\": 76.30,\n    \"2025-09-15\": 74.80,\n    \"2025-09-01\": 73.20,\n}\n\nPRICE_SOURCE_URL = \"https://tradingeconomics.com/commodity/carbon\"\n\nDEFAULT_EMISSIONS = {\n    \"steel\": 2.3,\n    \"aluminum\": 8.6,\n    \"cement\": 0.9,\n    \"fertilizer\": 1.5,\n    \"electricity\": 0.4,\n    \"glass\": 0.8,\n    \"ceramics\": 0.7,\n    \"hydrogen\": 10.0,\n}\n\ndef write_price_to_stage(carbon_price, is_manual=False):\n    \"\"\"Write carbon price to a .txt file and upload to @Documents stage.\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    source_type = \"Manual override\" if is_manual else \"Default market price\"\n    \n    content = f\"\"\"Live EU ETS Carbon Price: â‚¬{carbon_price:.2f}/tonne COâ‚‚\nUpdated: {timestamp}\nSource: {source_type}\n\nThis price represents the current European Union Emissions Trading System (EU ETS) allowance price.\nUse this for CBAM cost calculations unless overridden by official EU guidance.\n\nCBAM Formula:\nCBAM Cost = (Embedded Emissions in tCOâ‚‚e) Ã— (EU ETS Price - Carbon Price Paid at Origin)\n\nNote: Prices fluctuate daily. Update regularly for accurate calculations.\n\"\"\"\n    \n    try:\n        with open(\"/tmp/live_carbon_price.txt\", \"w\") as f:\n            f.write(content)\n        session.file.put(\"/tmp/live_carbon_price.txt\", \"@Documents\", overwrite=True, auto_compress=False)\n        return True\n    except Exception as e:\n        st.error(f\"Failed to write price: {str(e)}\")\n        return False\n\ndef process(file_name: str):\n    \"\"\"Process document and extract text using OCR.\"\"\"\n    try:\n        query = \"\"\"\n            SELECT TO_VARCHAR(SNOWFLAKE.CORTEX.PARSE_DOCUMENT(?, ?, {'mode': 'OCR'}):content) AS OCR;\n        \"\"\"\n        resp = session.sql(query, params=[\"@Documents\", file_name]).collect()\n        text = resp[0]['OCR']\n        return pd.DataFrame({'TEXT': [text], 'FILE_NAME': file_name})\n    except Exception as e:\n        return pd.DataFrame({'TEXT': [''], 'FILE_NAME': file_name})\n\ndef reindex_documents():\n    \"\"\"Reindex all documents in the stage - only on first load.\"\"\"\n    try:\n        files = session.sql(\"LIST @Documents\").collect()\n        file_names = [file['name'].split('/')[-1] for file in files]\n        \n        if not file_names:\n            return False\n        \n        dataframes = []\n        for name in file_names:\n            df = process(name)\n            if not df.empty and df['TEXT'].iloc[0]:\n                dataframes.append(df)\n        \n        if dataframes:\n            final_dataframe = pd.concat(dataframes, ignore_index=True)\n            snowpark_df = session.create_dataframe(final_dataframe).select(col(\"FILE_NAME\"), col(\"TEXT\"))\n            snowpark_df.write.mode(\"overwrite\").save_as_table(\"docs_text_table\")\n            return True\n        return False\n    except:\n        return False\n\ndef init_messages():\n    \"\"\"Initialize session state variables.\"\"\"\n    if \"messages\" not in st.session_state:\n        st.session_state.messages = []\n    if \"last_request_time\" not in st.session_state:\n        st.session_state.last_request_time = 0\n    if \"carbon_price\" not in st.session_state:\n        st.session_state.carbon_price = DEFAULT_CARBON_PRICE\n    if \"is_manual_price\" not in st.session_state:\n        st.session_state.is_manual_price = False\n    if \"selected_historic_date\" not in st.session_state:\n        st.session_state.selected_historic_date = None\n    if \"manual_override_price\" not in st.session_state:\n        st.session_state.manual_override_price = None\n    if \"initialized\" not in st.session_state:\n        st.session_state.initialized = False\n        # Only reindex on first load\n        write_price_to_stage(DEFAULT_CARBON_PRICE, False)\n        reindex_documents()\n        st.session_state.initialized = True\n\ndef init_config_options():\n    \"\"\"Initialize UI configuration options.\"\"\"\n    st.session_state.num_chat_messages = history_length\n    \n    # Top row: Price display, reset, and clear chat\n    col1, col2, col3 = st.columns([3, 1, 1])\n    \n    with col1:\n        # Always show current market price (never changes)\n        st.metric(\n            \"Current EU ETS Price\", \n            f\"â‚¬{DEFAULT_CARBON_PRICE:.2f}/tCOâ‚‚e\"\n        )\n        # Show date stamp for default price\n        if st.session_state.manual_override_price is None and st.session_state.selected_historic_date is None:\n            st.caption(\"Using default price - Updated: 2024-11-01\")\n        \n        # Show alert when manual price is active\n        if st.session_state.manual_override_price is not None:\n            st.caption(f\"âš ï¸ Calculator is using manually entered price: â‚¬{st.session_state.manual_override_price:.2f}\")\n        \n        # Show alert when historic price is active\n        elif st.session_state.selected_historic_date is not None:\n            historic_price = RECENT_PRICES[st.session_state.selected_historic_date]\n            st.caption(f\"âš ï¸ Calculator is using historical price: â‚¬{historic_price:.2f}\")\n    \n    with col2:\n        # Reset button - always visible when not using default\n        if st.session_state.manual_override_price is not None or st.session_state.selected_historic_date is not None:\n            if st.button(\"ðŸ”„ Reset\", use_container_width=True):\n                st.session_state.carbon_price = DEFAULT_CARBON_PRICE\n                st.session_state.manual_override_price = None\n                st.session_state.selected_historic_date = None\n                write_price_to_stage(DEFAULT_CARBON_PRICE, False)\n                st.rerun()\n    \n    with col3:\n        if st.button(\"ðŸ—‘ï¸ Clear Chat\", use_container_width=True):\n            st.session_state.messages = []\n            st.rerun()\n    \n    # Price update section - always expanded\n    st.markdown(\"---\")\n    st.subheader(\"ðŸ’¶ Update Carbon Price\")\n    st.caption(\"Source: ICE Futures Europe & EEX (European Energy Exchange)\")\n    \n    # Historic price buttons in a row\n    st.write(\"**Historical Prices:**\")\n    cols = st.columns(len(RECENT_PRICES))\n    \n    for idx, (date, price) in enumerate(sorted(RECENT_PRICES.items(), reverse=True)):\n        with cols[idx]:\n            is_selected = st.session_state.selected_historic_date == date\n            button_type = \"primary\" if is_selected else \"secondary\"\n            \n            if st.button(\n                f\"{date}\\nâ‚¬{price:.2f}\", \n                key=f\"price_{date}\", \n                use_container_width=True,\n                type=button_type\n            ):\n                st.session_state.carbon_price = price\n                st.session_state.selected_historic_date = date\n                st.session_state.manual_override_price = None\n                write_price_to_stage(price, False)\n                st.rerun()\n    \n    st.divider()\n    \n    # Manual price input section\n    st.write(\"**Manual Price Entry:**\")\n    \n    # Determine if field should be disabled (greyed out when historic is selected)\n    is_field_disabled = st.session_state.selected_historic_date is not None\n    \n    # Set value to manual price if set, otherwise 0\n    if st.session_state.manual_override_price is not None:\n        default_val = st.session_state.manual_override_price\n    else:\n        default_val = 0.0\n    \n    col_input, col_button = st.columns([3, 1])\n    \n    with col_input:\n        new_price = st.number_input(\n            \"Enter current price (â‚¬/tCOâ‚‚e)\", \n            min_value=0.0, \n            max_value=500.0,\n            value=float(default_val),\n            step=0.5,\n            help=\"Enter a custom carbon price for calculations\",\n            key=\"price_input\",\n            disabled=is_field_disabled\n        )\n    \n    with col_button:\n        st.write(\"\")  # Spacing\n        st.write(\"\")  # Spacing\n        if st.button(\"âœ… Update Price\", use_container_width=True, disabled=is_field_disabled):\n            if new_price > 0:\n                st.session_state.carbon_price = new_price\n                st.session_state.manual_override_price = new_price\n                st.session_state.selected_historic_date = None\n                write_price_to_stage(new_price, True)\n                st.rerun()\n            else:\n                st.warning(\"Please enter a price greater than 0\")\n    \n    st.markdown(\"---\")\n    \n    # Emission factors reference\n    with st.expander(\"ðŸ“‹ Default Emission Factors\"):\n        st.write(\"**Default Embedded Emissions (tCOâ‚‚e per tonne of product)**\")\n        em_df = pd.DataFrame([\n            {\"Product\": k.title(), \"Emission Factor (tCOâ‚‚e/tonne)\": v}\n            for k, v in DEFAULT_EMISSIONS.items()\n        ])\n        st.dataframe(em_df, hide_index=True, use_container_width=True)\n        st.caption(\"These are used when specific emission data is not provided\")\n    \n    # Display chat history\n    for message in st.session_state.messages:\n        with st.chat_message(message[\"role\"]):\n            st.markdown(message[\"content\"])\n\ndef get_chat_history():\n    \"\"\"Get recent chat history for context.\"\"\"\n    start_index = max(0, len(st.session_state.messages) - st.session_state.num_chat_messages)\n    return st.session_state.messages[start_index : len(st.session_state.messages) - 1]\n\ndef extract_cbam_request(question):\n    \"\"\"Extract CBAM calculation parameters from user question.\"\"\"\n    match = re.search(r\"(\\d+(?:,\\d{3})*)\\s+tons?(?:\\s+of)?\\s+(\\w+)\", question, re.IGNORECASE)\n    emissions_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*tCO2e?(?:/ton)?\", question, re.IGNORECASE)\n    origin_price_match = re.search(r\"(?:origin|paid|cost).*?â‚¬?(\\d+(?:\\.\\d+)?)\", question, re.IGNORECASE)\n\n    if match:\n        quantity_str = match.group(1).replace(\",\", \"\")\n        quantity = int(quantity_str)\n        product = match.group(2).lower()\n    else:\n        quantity = None\n        product = None\n\n    emissions = float(emissions_match.group(1)) if emissions_match else None\n    origin_price = float(origin_price_match.group(1)) if origin_price_match else 0.0\n    \n    return product, quantity, emissions, origin_price\n\ndef calculate_cbam_cost(embedded_emissions, origin_carbon_price=0, eu_carbon_price=None):\n    \"\"\"Calculate CBAM cost based on emissions and carbon prices.\"\"\"\n    if eu_carbon_price is None:\n        eu_carbon_price = st.session_state.carbon_price\n    \n    cbam_cost = embedded_emissions * (eu_carbon_price - origin_carbon_price)\n    return max(0, cbam_cost)\n\ndef cortex_search(my_question):\n    \"\"\"Search documentation using Cortex Search Service.\"\"\"\n    try:\n        search_service = (root\n            .databases[database_name]\n            .schemas[schema_name]\n            .cortex_search_services[service_name]\n        )\n        resp = search_service.search(\n            query=my_question,\n            columns=[\"text\", \"file_name\"],\n            limit=num_results\n        )\n        results = json.loads(resp.to_json())[\"results\"]\n        prompt_context = \"\\n\\n\".join([r[\"text\"] for r in results]).replace(\"'\", \"\")\n        file_name = results[0]['file_name'] if results else \"No source\"\n        return prompt_context[:8000], file_name\n    except Exception as e:\n        st.error(f\"Search failed: {str(e)}\")\n        return \"\", \"Error\"\n\ndef format_chat_history(chat_history):\n    \"\"\"Format chat history for prompt context.\"\"\"\n    return \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in chat_history[-3:]])\n\ndef create_prompt(user_question):\n    \"\"\"Create prompt for LLM with context and instructions.\"\"\"\n    chat_history = get_chat_history()\n    history_str = format_chat_history(chat_history)\n    prompt_context, file_name = cortex_search(user_question)\n    \n    current_price = st.session_state.carbon_price\n\n    prompt = f\"\"\"You are a CBAM (Carbon Border Adjustment Mechanism) specialist. Provide direct, concise answers using the provided documentation.\n\n<context>\n{prompt_context}\n\nCurrent EU ETS Carbon Price: â‚¬{current_price:.2f}/tonne COâ‚‚e\n</context>\n\n<chat_history>\n{history_str}\n</chat_history>\n\n<question>\n{user_question}\n</question>\n\n<instructions>\n1. Answer directly from the provided documentation and current carbon price data.\n2. Cite specific values, formulas, and guidance from the documents.\n3. For CBAM calculations:\n   - Use default emission factors if actual emissions not provided: {DEFAULT_EMISSIONS}\n   - Formula: CBAM Cost = (Embedded Emissions tCOâ‚‚e) Ã— (EU ETS Price â‚¬{current_price:.2f} - Carbon Price Paid in Origin)\n   - Always show calculation steps clearly\n4. Keep responses under 150 words unless calculations require detail\n5. Structure: Direct answer â†’ Key requirements â†’ Calculations (if applicable) â†’ Limitations (if any)\n6. If information is missing: State what's needed clearly\n7. Be precise about deadlines, compliance requirements, and reporting obligations\n</instructions>\n\nResponse:\"\"\"\n    return prompt, file_name\n\ndef complete_with_retry(model, prompt, retries=2):\n    \"\"\"Call LLM completion with rate limiting and retry logic.\"\"\"\n    now = time.time()\n    if now - st.session_state.last_request_time < MIN_REQUEST_INTERVAL:\n        time.sleep(MIN_REQUEST_INTERVAL - (now - st.session_state.last_request_time))\n\n    for attempt in range(retries):\n        try:\n            response = complete(model, prompt)\n            st.session_state.last_request_time = time.time()\n            return response\n        except Exception as e:\n            if attempt < retries - 1:\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                st.error(f\"Request failed: {str(e)}\")\n                return None\n\ndef main():\n    st.title(\"ðŸŒ CBAM Calculator & Documentation Assistant\")\n    st.caption(\"Calculate Carbon Border Adjustment Mechanism costs with EU ETS pricing\")\n    \n    init_messages()\n    init_config_options()\n    \n    icons = {\"assistant\": \"â„ï¸\", \"user\": \"ðŸ‘¤\"}\n\n    if question := st.chat_input(\"Ask about CBAM calculations, emissions, or requirements...\"):\n        st.session_state.messages.append({\"role\": \"user\", \"content\": question})\n\n        with st.chat_message(\"user\", avatar=icons[\"user\"]):\n            st.markdown(question)\n\n        # Check for direct calculation request\n        product, quantity, emissions, origin_price = extract_cbam_request(question)\n        if product and quantity:\n            if emissions is None:\n                emissions = DEFAULT_EMISSIONS.get(product)\n            \n            if emissions is not None:\n                total_emissions = emissions * quantity\n                cbam_cost = calculate_cbam_cost(total_emissions, origin_price)\n                \n                eu_price = st.session_state.carbon_price\n                \n                response_text = f\"\"\"ðŸ’¶ **CBAM Cost Calculation**\n\n**Product:** {product.title()}  \n**Quantity:** {quantity:,} tonnes  \n**Emission Factor:** {emissions} tCOâ‚‚e/tonne  \n**Total Emissions:** {total_emissions:,.2f} tCOâ‚‚e  \n**EU ETS Price:** â‚¬{eu_price:.2f}/tCOâ‚‚e  \n**Origin Carbon Price:** â‚¬{origin_price:.2f}/tCOâ‚‚e  \n\n---\n\n**ðŸ’° Estimated CBAM Cost: â‚¬{cbam_cost:,.2f}**\n\n---\n\n*Calculation: {total_emissions:,.2f} tCOâ‚‚e Ã— (â‚¬{eu_price:.2f} - â‚¬{origin_price:.2f}) = â‚¬{cbam_cost:,.2f}*\n\nðŸ“ Note: This is an estimate. Actual CBAM liability depends on verified emissions data and official EU ETS prices at the time of import.\n\"\"\"\n                st.session_state.messages.append({\"role\": \"assistant\", \"content\": response_text})\n                with st.chat_message(\"assistant\", avatar=icons[\"assistant\"]):\n                    st.markdown(response_text)\n                return\n\n        # Handle documentation questions\n        with st.chat_message(\"assistant\", avatar=icons[\"assistant\"]):\n            with st.spinner(\"Analyzing documentation...\"):\n                prompt, file_name = create_prompt(question)\n                response = complete_with_retry(model_name, prompt)\n                if response:\n                    st.markdown(response)\n                    st.caption(f\"ðŸ“„ Source: {file_name}\")\n                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n\nif __name__ == \"__main__\":\n    main()"
  }
 ]
}